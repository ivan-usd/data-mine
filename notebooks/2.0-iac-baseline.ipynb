{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing for baseline values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [],
   "source": [
    "employee = pd.read_csv(\"../data/employee_cleaned.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Partition Data prior to testing baseline model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "X = employee.loc[:, employee.columns != 'LeaveOrNot']\n",
    "y = employee.loc[:, employee.columns == 'LeaveOrNot']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initializing Dummy Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Strategy implemented for this project is the uniform approach:\n",
    "“uniform”: generates predictions uniformly at random from the list of unique classes observed in y_train, i.e. each class has equal probability.\n",
    "Random State set to 7 for reproducibility"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "data": {
      "text/plain": "DummyClassifier(random_state=7, strategy='uniform')"
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy='uniform', random_state = 7)\n",
    "dummy_clf.fit(X_train,y_train.values.ravel())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Storing predicted results for baseline metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [
    "# Check for Model Accuracy\n",
    "y_pred = dummy_clf.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    0    1  Total\n",
      "Actual                    \n",
      "0          338  312    650\n",
      "1          224  232    456\n",
      "Total      562  544   1106\n"
     ]
    }
   ],
   "source": [
    "ypred = pd.crosstab(y_test['LeaveOrNot'], y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "ypred['Total'] = ypred.sum(axis=1);\n",
    "ypred.loc['Total'] = ypred.sum()\n",
    "print(ypred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [
    "TP = ypred[1][1]\n",
    "TN = ypred[0][0]\n",
    "FP = ypred[1][0]\n",
    "FN = ypred[0][1]\n",
    "TAN = TN + FP\n",
    "TAP = FN + TP\n",
    "TPN = TN + FN\n",
    "TPP = FP + TP\n",
    "GT = ypred['Total']['Total']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [],
   "source": [
    "accuracy = round((TN + TP) / GT, 4)\n",
    "sensitivity = round(TP / TAP, 4)\n",
    "specificity = round(TN / TAN, 4)\n",
    "precision = round(TP / TPP, 4)\n",
    "recall = round(TP / (TP + FN), 4)\n",
    "pxr = precision * recall\n",
    "ppr = precision + recall\n",
    "F1 = round((pxr / ppr) * 2, 4)\n",
    "F2 = round((pxr / ((4 * precision) + recall)) * 5, 4)\n",
    "F05 = round((pxr / ((0.25 * precision) + recall)) * 1.25, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════════════════╤═══════════════════════════════════════════════════╤═════════╕\n",
      "│ Evaluation Measure   │ Formula                                           │   Value │\n",
      "╞══════════════════════╪═══════════════════════════════════════════════════╪═════════╡\n",
      "│ Accuracy             │ (TN+TP)/GT                                        │  0.5154 │\n",
      "├──────────────────────┼───────────────────────────────────────────────────┼─────────┤\n",
      "│ Error rate           │ 1-Accuracy                                        │  0.4846 │\n",
      "├──────────────────────┼───────────────────────────────────────────────────┼─────────┤\n",
      "│ Sensitivity = Recall │ TP/TAP                                            │  0.5088 │\n",
      "├──────────────────────┼───────────────────────────────────────────────────┼─────────┤\n",
      "│ Specificity          │ TN/TAN                                            │  0.52   │\n",
      "├──────────────────────┼───────────────────────────────────────────────────┼─────────┤\n",
      "│ Precision            │ TP/TPP                                            │  0.4265 │\n",
      "├──────────────────────┼───────────────────────────────────────────────────┼─────────┤\n",
      "│ F1                   │ 2*(precision*recall)/(precision+recall)           │  0.464  │\n",
      "├──────────────────────┼───────────────────────────────────────────────────┼─────────┤\n",
      "│ F2                   │ 5*(precision*recall)/((4*precision)+recall)       │  0.4899 │\n",
      "├──────────────────────┼───────────────────────────────────────────────────┼─────────┤\n",
      "│ F0.5                 │ 1.25*(precision*recall)/((0.25*precision)+recall) │  0.4408 │\n",
      "╘══════════════════════╧═══════════════════════════════════════════════════╧═════════╛\n"
     ]
    }
   ],
   "source": [
    "data = [[\"Accuracy\", \"(TN+TP)/GT\", accuracy], [\"Error rate\", \"1-Accuracy\", 1 - accuracy],\n",
    "        [\"Sensitivity = Recall\", \"TP/TAP\", sensitivity], [\"Specificity\", \"TN/TAN\", specificity],\n",
    "        [\"Precision\", \"TP/TPP\", precision], [\"F1\", \"2*(precision*recall)/(precision+recall)\", F1],\n",
    "        [\"F2\", \"5*(precision*recall)/((4*precision)+recall)\", F2],\n",
    "        [\"F0.5\", \"1.25*(precision*recall)/((0.25*precision)+recall)\", F05]]\n",
    "col_names = [\"Evaluation Measure\", \"Formula\", \"Value\"]\n",
    "print(tabulate(data, headers=col_names, tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}